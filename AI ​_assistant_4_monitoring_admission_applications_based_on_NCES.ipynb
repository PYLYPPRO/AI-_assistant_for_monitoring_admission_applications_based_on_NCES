{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import os\n",
        "import json\n",
        "\n",
        "# --- Конфігурація ---\n",
        "# Назва файлу для збереження агрегованих даних (історії)\n",
        "AGGREGATED_DATA_FILE = 'aggregated_applicant_data.csv'\n",
        "# Назва папки для збереження діаграм\n",
        "PLOTS_DIR = 'applicant_plots_nces'\n",
        "# Назва файлу з даними NCES, який ви завантажите\n",
        "# ЗМІНІТЬ ЦЕ, ЯКЩО ВАШ ФАЙЛ МАЄ ІНШУ НАЗВУ!\n",
        "NCES_DATA_FILE = 'nces_admissions_data.csv'\n",
        "# Назва університету, який ми будемо аналізувати\n",
        "TARGET_UNIVERSITY = 'University of Chicago'\n",
        "\n",
        "# --- Функції для отримання та парсингу даних NCES ---\n",
        "\n",
        "def create_mock_nces_data(filename=NCES_DATA_FILE):\n",
        "    \"\"\"\n",
        "    Створює фіктивний CSV-файл, що імітує дані NCES IPEDS.\n",
        "    У реальному сценарії ви завантажите цей файл з веб-сайту NCES.\n",
        "    \"\"\"\n",
        "    if os.path.exists(filename):\n",
        "        print(f\"Фіктивний файл '{filename}' вже існує. Пропускаємо створення.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Створення фіктивного файлу NCES даних: {filename}\")\n",
        "    data = {\n",
        "        'UNITID': [144050, 144050, 144050, 144050, 144050],\n",
        "        'INSTNM': ['University of Chicago', 'University of Chicago', 'University of Chicago', 'University of Chicago', 'University of Chicago'],\n",
        "        'APPLCNT': [35000, 36500, 38000, 39500, 41000], # Загальна кількість заявок\n",
        "        'ADMSSN': [3000, 3100, 3200, 3300, 3400], # Прийняті\n",
        "        'ENRLT': [2000, 2100, 2200, 2300, 2400], # Зараховані\n",
        "        'MAJOR_CS_APPL': [8000, 8500, 9000, 9500, 10000], # Фіктивні заявки на Комп'ютерні науки\n",
        "        'MAJOR_ECON_APPL': [7500, 7800, 8100, 8400, 8700], # Фіктивні заявки на Економіку\n",
        "        'MAJOR_BIO_APPL': [7000, 7200, 7400, 7600, 7800], # Фіктивні заявки на Біологію\n",
        "        'STATE_IL_APPL': [10000, 10500, 11000, 11500, 12000], # Фіктивні заявки з Іллінойсу\n",
        "        'STATE_CA_APPL': [8000, 8300, 8600, 8900, 9200], # Фіктивні заявки з Каліфорнії\n",
        "        'STATE_NY_APPL': [7000, 7200, 7400, 7600, 7800], # Фіктивні заявки з Нью-Йорка\n",
        "        'YEAR': [2019, 2020, 2021, 2022, 2023] # Рік даних\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"Фіктивний файл '{filename}' успішно створено.\")\n",
        "\n",
        "def fetch_and_parse_nces_data(nces_filename=NCES_DATA_FILE, target_university=TARGET_UNIVERSITY):\n",
        "    \"\"\"\n",
        "    Завантажує дані з локального файлу NCES CSV та парсить їх.\n",
        "    ЦЯ ФУНКЦІЯ ПОВИННА БУТИ АДАПТОВАНА ПІД РЕАЛЬНІ НАЗВИ СТОВПЦІВ У ВАШОМУ ФАЙЛІ NCES!\n",
        "    \"\"\"\n",
        "    if not os.path.exists(nces_filename):\n",
        "        print(f\"Помилка: Файл NCES даних '{nces_filename}' не знайдено.\")\n",
        "        print(\"Будь ласка, завантажте відповідний CSV-файл з NCES IPEDS та розмістіть його у тій же папці, що й скрипт.\")\n",
        "        print(\"Або запустіть скрипт, щоб створити фіктивні дані для демонстрації.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Читання даних з файлу NCES: {nces_filename}\")\n",
        "    try:\n",
        "        df_nces = pd.read_csv(nces_filename)\n",
        "    except Exception as e:\n",
        "        print(f\"Помилка при читанні файлу NCES: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Фільтруємо дані для цільового університету\n",
        "    df_university = df_nces[df_nces['INSTNM'] == target_university].copy()\n",
        "\n",
        "    if df_university.empty:\n",
        "        print(f\"Не знайдено даних для '{target_university}' у файлі NCES. Перевірте назву університету або дані.\")\n",
        "        return None\n",
        "\n",
        "    # Стовпці, які потрібно витягти.\n",
        "    # ЗМІНІТЬ ЦІ НАЗВИ СТОВПЦІВ ВІДПОВІДНО ДО ВАШОГО РЕАЛЬНОГО ФАЙЛУ NCES!\n",
        "    total_applicants_col = 'APPLCNT'\n",
        "    year_col = 'YEAR'\n",
        "\n",
        "    # Приклад: витягуємо дані про спеціальності та штати з фіктивних стовпців\n",
        "    # У РЕАЛЬНИХ ДАНИХ NCES ЦІ СТОВПЦІ МОЖУТЬ МАТИ ІНШІ НАЗВИ АБО БУТИ ВІДСУТНІМИ ДЛЯ ЗАЯВОК!\n",
        "    # Можливо, вам доведеться агрегувати дані з різних таблиць IPEDS.\n",
        "    majors_data_cols = {\n",
        "        'Комп\\'ютерні науки': 'MAJOR_CS_APPL',\n",
        "        'Економіка': 'MAJOR_ECON_APPL',\n",
        "        'Біологія': 'MAJOR_BIO_APPL'\n",
        "    }\n",
        "    states_data_cols = {\n",
        "        'Іллінойс': 'STATE_IL_APPL',\n",
        "        'Каліфорнія': 'STATE_CA_APPL',\n",
        "        'Нью-Йорк': 'STATE_NY_APPL'\n",
        "    }\n",
        "\n",
        "    parsed_data_list = []\n",
        "    for index, row in df_university.iterrows():\n",
        "        year = row[year_col]\n",
        "        total_applicants = row.get(total_applicants_col, 0) # Використовуємо .get для безпеки\n",
        "\n",
        "        majors_dist = {name: row.get(col, 0) for name, col in majors_data_cols.items()}\n",
        "        states_dist = {name: row.get(col, 0) for name, col in states_data_cols.items()}\n",
        "\n",
        "        parsed_data_list.append({\n",
        "            'timestamp': datetime(year, 1, 1).isoformat(), # Використовуємо 1 січня для року\n",
        "            'year': year,\n",
        "            'total_applicants': total_applicants,\n",
        "            'majors': majors_dist,\n",
        "            'states': states_dist\n",
        "        })\n",
        "    return parsed_data_list\n",
        "\n",
        "# --- Функції для збереження та завантаження агрегованих даних ---\n",
        "\n",
        "def save_aggregated_data(new_data_list, filename=AGGREGATED_DATA_FILE):\n",
        "    \"\"\"\n",
        "    Зберігає нові агреговані дані у CSV-файл. Якщо файл існує, додає нові рядки.\n",
        "    Складні словники (majors, states) зберігаються як JSON-рядки.\n",
        "    \"\"\"\n",
        "    if not new_data_list:\n",
        "        print(\"Немає нових агрегованих даних для збереження.\")\n",
        "        return\n",
        "\n",
        "    # Перетворюємо словники на JSON-рядки для збереження в CSV\n",
        "    data_to_save = []\n",
        "    for item in new_data_list:\n",
        "        data_to_save.append({\n",
        "            'timestamp': item['timestamp'],\n",
        "            'year': item['year'],\n",
        "            'total_applicants': item['total_applicants'],\n",
        "            'majors': json.dumps(item['majors'], ensure_ascii=False),\n",
        "            'states': json.dumps(item['states'], ensure_ascii=False)\n",
        "        })\n",
        "\n",
        "    df_new = pd.DataFrame(data_to_save)\n",
        "\n",
        "    if os.path.exists(filename):\n",
        "        df_existing = pd.read_csv(filename)\n",
        "        # Об'єднуємо, уникаючи дублікатів за роком/timestamp\n",
        "        df_combined = pd.concat([df_existing, df_new]).drop_duplicates(subset=['year']).reset_index(drop=True)\n",
        "    else:\n",
        "        df_combined = df_new\n",
        "\n",
        "    df_combined.to_csv(filename, index=False)\n",
        "    print(f\"Агреговані дані успішно збережено у {filename}\")\n",
        "\n",
        "def load_aggregated_data(filename=AGGREGATED_DATA_FILE):\n",
        "    \"\"\"\n",
        "    Завантажує всі збережені агреговані дані з CSV-файлу.\n",
        "    JSON-рядки перетворюються назад на словники.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"Файл агрегованих даних '{filename}' не знайдено. Починаємо з чистого аркуша.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    df = pd.read_csv(filename)\n",
        "    # Перетворюємо JSON-рядки назад на словники\n",
        "    if 'majors' in df.columns:\n",
        "        df['majors'] = df['majors'].apply(lambda x: json.loads(x) if pd.notna(x) else {})\n",
        "    if 'states' in df.columns:\n",
        "        df['states'] = df['states'].apply(lambda x: json.loads(x) if pd.notna(x) else {})\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    return df\n",
        "\n",
        "# --- Функції для аналізу та візуалізації ---\n",
        "\n",
        "def analyze_trends(df):\n",
        "    \"\"\"\n",
        "    Аналізує динаміку змін та виявляє тенденції.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        print(\"Недостатньо даних для аналізу тенденцій.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n--- Аналіз Тенденцій ---\")\n",
        "    df_sorted = df.sort_values(by='year').reset_index(drop=True)\n",
        "\n",
        "    if len(df_sorted) > 1:\n",
        "        latest_data = df_sorted.iloc[-1]\n",
        "        previous_data = df_sorted.iloc[-2]\n",
        "\n",
        "        # Динаміка загальної кількості\n",
        "        total_change = latest_data['total_applicants'] - previous_data['total_applicants']\n",
        "        total_percent_change = (total_change / previous_data['total_applicants']) * 100 if previous_data['total_applicants'] != 0 else 0\n",
        "        print(f\"Зміна загальної кількості заявок ({previous_data['year']} -> {latest_data['year']}): {total_change} ({total_percent_change:.2f}%)\")\n",
        "\n",
        "        # Тенденції за напрямками (показуємо топ-3 зміни)\n",
        "        print(\"\\nТенденції за напрямками:\")\n",
        "        majors_prev = previous_data['majors']\n",
        "        majors_curr = latest_data['majors']\n",
        "        major_changes = {}\n",
        "        for major, count_curr in majors_curr.items():\n",
        "            count_prev = majors_prev.get(major, 0)\n",
        "            change = count_curr - count_prev\n",
        "            percent_change = (change / count_prev) * 100 if count_prev != 0 else (100 if change > 0 else 0)\n",
        "            major_changes[major] = {'change': change, 'percent_change': percent_change}\n",
        "\n",
        "        sorted_major_changes = sorted(major_changes.items(), key=lambda item: abs(item[1]['change']), reverse=True)\n",
        "        for major, data in sorted_major_changes[:3]:\n",
        "            print(f\"  {major}: Зміна {data['change']} ({data['percent_change']:.2f}%)\")\n",
        "\n",
        "        # Тенденції за штатами (показуємо топ-3 зміни)\n",
        "        print(\"\\nТенденції за штатами:\")\n",
        "        states_prev = previous_data['states']\n",
        "        states_curr = latest_data['states']\n",
        "        state_changes = {}\n",
        "        for state, count_curr in states_curr.items():\n",
        "            count_prev = states_prev.get(state, 0)\n",
        "            change = count_curr - count_prev\n",
        "            percent_change = (change / count_prev) * 100 if count_prev != 0 else (100 if change > 0 else 0)\n",
        "            state_changes[state] = {'change': change, 'percent_change': percent_change}\n",
        "\n",
        "        sorted_state_changes = sorted(state_changes.items(), key=lambda item: abs(item[1]['change']), reverse=True)\n",
        "        for state, data in sorted_state_changes[:3]:\n",
        "            print(f\"  {state}: Зміна {data['change']} ({data['percent_change']:.2f}%)\")\n",
        "    else:\n",
        "        print(\"Потрібно більше даних (мінімум 2 записи) для розрахунку тенденцій.\")\n",
        "\n",
        "def visualize_data(df, plots_dir=PLOTS_DIR):\n",
        "    \"\"\"\n",
        "    Будує діаграми на основі зібраних даних.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        print(\"Немає даних для візуалізації.\")\n",
        "        return\n",
        "\n",
        "    os.makedirs(plots_dir, exist_ok=True)\n",
        "    print(f\"\\nЗбереження діаграм у папку: {plots_dir}\")\n",
        "\n",
        "    # 1. Динаміка загальної кількості заявок\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.lineplot(x='year', y='total_applicants', data=df, marker='o')\n",
        "    plt.title('Динаміка Загальної Кількість Заявок (за даними NCES)', fontsize=16)\n",
        "    plt.xlabel('Рік', fontsize=12)\n",
        "    plt.ylabel('Кількість Заявок', fontsize=12)\n",
        "    plt.grid(True)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(plots_dir, 'total_applicants_dynamics_nces.png'))\n",
        "    plt.close()\n",
        "    print(\"  - Збережено: total_applicants_dynamics_nces.png\")\n",
        "\n",
        "    # 2. Розподіл за напрямками навчання (для останнього року)\n",
        "    latest_majors = df.iloc[-1]['majors']\n",
        "    if latest_majors:\n",
        "        majors_df = pd.DataFrame(list(latest_majors.items()), columns=['Напрямок', 'Кількість'])\n",
        "        plt.figure(figsize=(12, 7))\n",
        "        sns.barplot(x='Кількість', y='Напрямок', data=majors_df.sort_values(by='Кількість', ascending=False), palette='viridis')\n",
        "        plt.title(f\"Розподіл Заявок за Напрямками Навчання ({df.iloc[-1]['year']} рік)\", fontsize=16)\n",
        "        plt.xlabel('Кількість Заявок', fontsize=12)\n",
        "        plt.ylabel('Напрямок', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(plots_dir, 'majors_distribution_nces.png'))\n",
        "        plt.close()\n",
        "        print(\"  - Збережено: majors_distribution_nces.png\")\n",
        "    else:\n",
        "        print(\"  - Немає даних для розподілу за напрямками.\")\n",
        "\n",
        "    # 3. Розподіл за штатами (для останнього року)\n",
        "    latest_states = df.iloc[-1]['states']\n",
        "    if latest_states:\n",
        "        states_df = pd.DataFrame(list(latest_states.items()), columns=['Штат', 'Кількість'])\n",
        "        plt.figure(figsize=(12, 7))\n",
        "        sns.barplot(x='Кількість', y='Штат', data=states_df.sort_values(by='Кількість', ascending=False), palette='magma')\n",
        "        plt.title(f\"Розподіл Абітурієнтів за Штатами ({df.iloc[-1]['year']} рік)\", fontsize=16)\n",
        "        plt.xlabel('Кількість Абітурієнтів', fontsize=12)\n",
        "        plt.ylabel('Штат', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(plots_dir, 'states_distribution_nces.png'))\n",
        "        plt.close()\n",
        "        print(\"  - Збережено: states_distribution_nces.png\")\n",
        "    else:\n",
        "        print(\"  - Немає даних для розподілу за штатами.\")\n",
        "\n",
        "# --- Основна логіка скрипта ---\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Основна функція, яка виконує весь процес:\n",
        "    1. Створює фіктивний файл NCES (якщо його немає).\n",
        "    2. Отримує та парсить дані з файлу NCES.\n",
        "    3. Зберігає агреговані дані.\n",
        "    4. Завантажує всі агреговані дані.\n",
        "    5. Аналізує тенденції.\n",
        "    6. Візуалізує дані.\n",
        "    \"\"\"\n",
        "    print(\"Початок роботи ШІ-асистента для моніторингу заявок на вступ (на основі NCES).\")\n",
        "\n",
        "    # 1. Створення фіктивного файлу NCES для демонстрації\n",
        "    create_mock_nces_data()\n",
        "\n",
        "    # 2. Отримання та парсинг даних з файлу NCES\n",
        "    # Цей крок поверне список словників, по одному для кожного року, знайденого в NCES файлі\n",
        "    parsed_nces_data_list = fetch_and_parse_nces_data()\n",
        "    if not parsed_nces_data_list:\n",
        "        print(\"Не вдалося отримати або розпарсити дані NCES. Завершення роботи.\")\n",
        "        return\n",
        "\n",
        "    # 3. Збереження агрегованих даних (історії)\n",
        "    save_aggregated_data(parsed_nces_data_list)\n",
        "\n",
        "    # 4. Завантаження всіх історичних даних\n",
        "    all_data_df = load_aggregated_data()\n",
        "\n",
        "    # 5. Аналіз тенденцій\n",
        "    analyze_trends(all_data_df)\n",
        "\n",
        "    # 6. Візуалізація даних\n",
        "    visualize_data(all_data_df)\n",
        "\n",
        "    print(\"\\nРобота ШІ-асистента завершена. Перевірте файли .csv та .png у відповідних папках.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Початок роботи ШІ-асистента для моніторингу заявок на вступ (на основі NCES).\n",
            "Створення фіктивного файлу NCES даних: nces_admissions_data.csv\n",
            "Фіктивний файл 'nces_admissions_data.csv' успішно створено.\n",
            "Читання даних з файлу NCES: nces_admissions_data.csv\n",
            "Агреговані дані успішно збережено у aggregated_applicant_data.csv\n",
            "\n",
            "--- Аналіз Тенденцій ---\n",
            "Зміна загальної кількості заявок (2022 -> 2023): 1500 (3.80%)\n",
            "\n",
            "Тенденції за напрямками:\n",
            "  Комп'ютерні науки: Зміна 500 (5.26%)\n",
            "  Економіка: Зміна 300 (3.57%)\n",
            "  Біологія: Зміна 200 (2.63%)\n",
            "\n",
            "Тенденції за штатами:\n",
            "  Іллінойс: Зміна 500 (4.35%)\n",
            "  Каліфорнія: Зміна 300 (3.37%)\n",
            "  Нью-Йорк: Зміна 200 (2.63%)\n",
            "\n",
            "Збереження діаграм у папку: applicant_plots_nces\n",
            "  - Збережено: total_applicants_dynamics_nces.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1960578048.py:246: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x='Кількість', y='Напрямок', data=majors_df.sort_values(by='Кількість', ascending=False), palette='viridis')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Збережено: majors_distribution_nces.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1960578048.py:262: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x='Кількість', y='Штат', data=states_df.sort_values(by='Кількість', ascending=False), palette='magma')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Збережено: states_distribution_nces.png\n",
            "\n",
            "Робота ШІ-асистента завершена. Перевірте файли .csv та .png у відповідних папках.\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "id": "-pNEX-kfaZi1",
        "outputId": "3f64c659-bbf8-4716-f03a-727be6256212",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}